# Configuration settings for HGAN
# Note: Use 1/0 for boolean variables

[video]
# How many frames do we generate for each of the real/fake videos?
# ('K' in MocoGAN paper figure 2)
generator_frames = 30

# How many consecutive frames do we inspect for each of the real/fake input videos?
# ('T' in MocoGAN paper figure 2)
# Should be <= <generator_frames>
# Should be divisible by 16 since
#   Discriminator_V is doing nn.Linear(int((ndf*8)*(T/16)*6*6), 1)
discriminator_frames = 16

# How many real video frames do we generate for each system before sampling
# <generator_frames> frames out of it?
# TODO: This should be 512 according to Blanchette 2021 but there's no
# reason for this to be anything other than <generator_frames> since all trajectories
# are randomly initialized anyway.
real_total_frames = 30

# Convert to values between -1 and +1 ?
normalize = 0

[paths]
# base wrt which all input/output folders are determined
# include trailing slash
# input folder is irrelevant when generating realtime datasets
#   (i.e. when [experiment].rt_data_generator is not blank)
input = /path/to/input/folder/
output = /media/vineetb/T7/cablanc/runs/hgan0/

[experiment]

# Default GPU ID to use. Leave blank to use CPU.
gpu = 0

# One of mass_spring/pendulum/double_pendulum/two_body/three_body
# If not specified (None), implies variable system
system_name = mass_spring
# Are the physical properties of the system constant?
system_physics_constant = 1
# Are the colors of the system constant?
system_color_constant = 1
# Does the system have friction? (0=conservative system)
system_friction = 0

# One of gru/hnn_simple/hnn_phase_space/hnn_mass
architecture = hnn_phase_space

n_epoch = 50000
batch_size = 16
cyclic_coord_loss = 0.01
learning_rate = 0.0002
betas = 0.5, 0.999

# Gamma for regularization of GAN loss
# see https://arxiv.org/pdf/1801.04406v4.pdf, Eq (9)
# Set 0 for no regularization
r1_gamma = 10

# we print diagnostics after every print_every epochs
print_every = 10
# we save trained models every save_model_every epochs
save_model_every = 100
# we save real videos every save_real_video_every epochs
save_real_video_every = 100
# we save fake videos every save_fake_video_every epochs
save_fake_video_every = 100
# we calculate fvd distance (expensive operation) every calculate_fvd_every epochs
calculate_fvd_every = 1000000

seed = 0
retrain = 1

# Specify wandb API Key (from https://wandb.ai/authorize) if using wandb, otherwise leave blank
wandb_api_key =
# wandb_api_key = 905efe53a498711a158de312a8e46f77e8424185

# One of 'dm'/'hgn'/<blank>
rt_data_generator = hgn

img_size = 96
hidden_size = 100
# Dimension of epsilon (q, p) vector
ndim_epsilon = 20
# Dimension of content vector for discriminator
ndim_content = 50
# Dimension of label embedding in Discriminators/Generator (appended to the end of de)
# Note that the max. number of "systems" supported by dm_hamiltonian_dynamics_suite is 11
ndim_label = 3
# Dimension of color vector in Discriminators/Generator (appended to the end of de)
ndim_color = 9
# Dimension of physical properties vector for discriminator (appended to the end of de)
# e.g. 4 for mass_spring
ndim_physics = 10
# Number of channels
ndim_channel = 3
# Number of Discriminator filters (from dcgan)
ndim_discriminator_filter = 32
# Number of Generator filters
ndim_generator_filter = 32

# Multiplication factor (~1.0) applied to generator loss for fake data
generator_gamma = 1.0
# Multiplication factor (~1.0) applied to discriminator loss for real data
discriminator_gamma = 0.7

[test]
# A section purely for testing purposes

astring = bar
abool = 0
aint = 42
amissing =
