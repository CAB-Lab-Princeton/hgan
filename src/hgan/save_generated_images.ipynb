{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c41fa4-b1c2-49ef-bc5d-9c73e9dad096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up model like in CampusAI/Hamiltonian-Generative-Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7cd41766-9e3a-429e-a6e7-ff30ef775166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import argparse\n",
    "import copy\n",
    "import pprint\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from utilities.integrator import Integrator\n",
    "from utilities.training_logger import TrainingLogger\n",
    "from utilities import loader\n",
    "from utilities.loader import load_hgn, get_online_dataloaders, get_offline_dataloaders\n",
    "from utilities.losses import reconstruction_loss, kld_loss, geco_constraint\n",
    "from utilities.statistics import mean_confidence_interval\n",
    "from train import _read_config, _merge_configs, _ask_confirmation, _overwrite_config_with_cmd_arguments, HgnTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f99bcae5-d17b-40e4-86ad-0c73bd19aea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with OFFLINE data...\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_TRAIN_CONFIG_FILE = \"experiment_params/train_config_default.yaml\"\n",
    "DEFAULT_DATASET_CONFIG_FILE = \"experiment_params/dataset_offline_default.yaml\"\n",
    "DEFAULT_ENVIRONMENTS_PATH = \"experiment_params/default_environments/\"\n",
    "DEFAULT_SAVE_MODELS_DIR = \"saved_models/\"\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--train-config', action='store', nargs=1, type=str, required=True,\n",
    "    help=f'Path to the training configuration yaml file.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--dataset-config', action='store', nargs=1, type=str, required=False,\n",
    "    help=f'Path to the dataset configuration yaml file.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--name', action='store', nargs=1, required=False,\n",
    "    help='If specified, this name will be used instead of experiment_id of the yaml file.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--epochs', action='store', nargs=1, type=int, required=False,\n",
    "    help='The number of training epochs. If not specified, optimization.epochs of the '\n",
    "         'training configuration will be used.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--env', action='store', nargs=1, type=str, required=False,\n",
    "    help='The environment to use (for online training only). Possible values are '\n",
    "         '\\'pendulum\\', \\'spring\\', \\'two_bodies\\', \\'three_bodies\\', corresponding to '\n",
    "         'environment configurations in experiment_params/default_environments/. If not '\n",
    "         'specified, the environment specified in the given --dataset-config will be used.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--dataset-path', action='store', nargs=1, type=str, required=False,\n",
    "    help='Path to a stored dataset to use for training. For offline training only. In this '\n",
    "         'case no dataset configuration file will be loaded.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--params', action='store', nargs='+', required=False,\n",
    "    help='Override one or more parameters in the config. The format of an argument is '\n",
    "         'param_name=param_value. Nested parameters are accessible by using a dot, '\n",
    "         'i.e. --param dataset.img_size=32. IMPORTANT: lists must be enclosed in double '\n",
    "         'quotes, i.e. --param environment.mass:\"[0.5, 0.5]\".'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-y', '-y', action='store_true', default=False, required=False,\n",
    "    help='Whether to skip asking for user confirmation before starting the training.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--resume', action='store', required=False, nargs='?', default=None,\n",
    "    help='NOT IMPLEMENTED YET. Resume the training from a saved model. If a path is provided, '\n",
    "         'the training will be resumed from the given checkpoint. Otherwise, the last '\n",
    "         'checkpoint will be taken from saved_models/<experiment_id>.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--load', action='store', type=str, required=False, nargs=1,\n",
    "    help='Path from which to load the HGN.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--reset', action='store', nargs='+', required=False,\n",
    "    help='Use only in combimation with --load, tells the trainer to reinstantiate the given '\n",
    "         'networks. Values: \\'encoder\\', \\'transformer\\', \\'decoder\\', \\'hamiltonian\\'.'\n",
    ")\n",
    "\n",
    "sys.argv = ['foo',\n",
    "           '--train-config', DEFAULT_TRAIN_CONFIG_FILE,\n",
    "           '--dataset-config', DEFAULT_DATASET_CONFIG_FILE,\n",
    "           '-y']\n",
    "\n",
    "_args = parser.parse_args()\n",
    "\n",
    "# Read configurations\n",
    "_train_config = _read_config(_args.train_config[0])\n",
    "if _args.dataset_path is None:  # Will use the dataset config file (or default if not given)\n",
    "    _dataset_config_file = DEFAULT_DATASET_CONFIG_FILE if _args.dataset_config is None else \\\n",
    "        _args.dataset_config[0]\n",
    "    _dataset_config = _read_config(_dataset_config_file)\n",
    "    _config = _merge_configs(_train_config, _dataset_config)\n",
    "else:  # Will use the dataset given in the command line arguments\n",
    "    assert _args.dataset_config is None, 'Both --dataset-path and --dataset-config were given.'\n",
    "    _config = _train_config\n",
    "\n",
    "# Overwrite configuration with command line arguments\n",
    "_overwrite_config_with_cmd_arguments(_config, _args)\n",
    "\n",
    "# Show configuration and ask user for confirmation\n",
    "if not _args.y:\n",
    "    _ask_confirmation(_config)\n",
    "\n",
    "# Train HGN network\n",
    "trainer = HgnTrainer(_config, resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "963848d7-ec04-45d4-b00a-cb269a220c08",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'environment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [100]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menvironment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'environment'"
     ]
    }
   ],
   "source": [
    "_config['environment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "512b8bbe-e93f-4bbf-a9a9-3b42cd96c950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hgn model, which were saved? can we look at all saved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ace2eb4d-91a4-41f5-9bd7-c46c8411b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'mass_spring_multi_colors'\n",
    "save_path = '/data/ca15/hgn-pytorch/saved_models/'\n",
    "load_path = save_path + dataset_name + '_checkpoint_10000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7f559334-1013-42e1-aee1-509ec4c9ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "params['load_path'] = load_path\n",
    "params['reset'] = []\n",
    "params['device'] = trainer.device\n",
    "params['dtype'] = trainer.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4adb190d-b568-4dfc-b164-c75fc01511bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_and_reset(params, params['device'], params['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ea3471ab-fc7d-4501-900d-f1cc82fa7b06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 3, 32, 32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train_image = next(iter(trainer.test_data_loader))\n",
    "train_image = trainer.test_data_loader.dataset[10]\n",
    "train_image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "901de555-1b72-4412-8cd8-19b14c7e9376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x600 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "np_train_image = train_image.transpose(0,2,3,1)\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(1,16,1)\n",
    "plt.imshow(np_train_image[0])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,2)\n",
    "plt.imshow(np_train_image[1])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,3)\n",
    "plt.imshow(np_train_image[2])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,4)\n",
    "plt.imshow(np_train_image[3])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,5)\n",
    "plt.imshow(np_train_image[4])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,6)\n",
    "plt.imshow(np_train_image[5])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,7)\n",
    "plt.imshow(np_train_image[6])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,8)\n",
    "plt.imshow(np_train_image[7])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,9)\n",
    "plt.imshow(np_train_image[8])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,10)\n",
    "plt.imshow(np_train_image[9])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,11)\n",
    "plt.imshow(np_train_image[10])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,12)\n",
    "plt.imshow(np_train_image[11])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,13)\n",
    "plt.imshow(np_train_image[12])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,14)\n",
    "plt.imshow(np_train_image[13])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,15)\n",
    "plt.imshow(np_train_image[14])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,16)\n",
    "plt.imshow(np_train_image[15])\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e2bbdb2b-836c-4fad-bc6a-0c9f8dfe5e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 34, 3, 32, 32])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_image = torch.Tensor(train_image).unsqueeze(0).to(trainer.device).type(trainer.dtype)\n",
    "train_image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d31093d7-0daa-406f-a438-7710981adaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 5 29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rollout_len = train_image.shape[1]\n",
    "input_frames = trainer.params['optimization']['input_frames']\n",
    "n_frames = rollout_len - input_frames\n",
    "print(rollout_len, input_frames, n_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b657514f-d58e-42d5-b05e-f9a2cc4e750f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 3, 32, 32])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hgn_output = trainer.hgn.forward(rollout_batch=train_image[:, :input_frames], n_steps=n_frames)\n",
    "prediction = hgn_output.reconstructed_rollout\n",
    "prediction.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0dd0c1c5-5390-4b3c-9e61-1af0d36b4a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99957734, 1.0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np_prediction = prediction[0].permute(0,2,3,1).detach().cpu().numpy()\n",
    "np_prediction.shape\n",
    "np_prediction.min(), np_prediction.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "512f6e97-562d-4f03-8931-5660e5d987b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABiEAAABlCAYAAAArmEBWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAECUlEQVR4nO3cQYrjQAAEwdUy//9y73WP9liJipmIswUNhQ4iaV/nnPMHAAAAAADgZn+fPgAAAAAAAPAziRAAAAAAAEBChAAAAAAAABIiBAAAAAAAkBAhAAAAAACAhAgBAAAAAAAkRAgAAAAAACAhQgAAAAAAAImvV394zinP8Wtc1/XR83a4hx022GGDHTZ8soMN7uFd2GCHDXbYYIcNdthghw122GCHDXbY4Fv6ea9s4CYEAAAAAACQECEAAAAAAIDEy3/H9L/PLhv9PtXFHju8xw4b7LDBDhuKHWzwHu/CBjtssMMGO2ywwwY7bLDDBjtssMMG39LPe3cDNyEAAAAAAICECAEAAAAAACRECAAAAAAAICFCAAAAAAAACRECAAAAAABIiBAAAAAAAEBChAAAAAAAABIiBAAAAAAAkBAhAAAAAACAhAgBAAAAAAAkRAgAAAAAACAhQgAAAAAAAAkRAgAAAAAASIgQAAAAAABAQoQAAAAAAAASIgQAAAAAAJAQIQAAAAAAgIQIAQAAAAAAJEQIAAAAAAAgIUIAAAAAAAAJEQIAAAAAAEiIEAAAAAAAQEKEAAAAAAAAEiIEAAAAAACQECEAAAAAAICECAEAAAAAACRECAAAAAAAICFCAAAAAAAACRECAAAAAABIiBAAAAAAAEBChAAAAAAAABIiBAAAAAAAkBAhAAAAAACAhAgBAAAAAAAkRAgAAAAAACAhQgAAAAAAAAkRAgAAAAAASIgQAAAAAABAQoQAAAAAAAASIgQAAAAAAJAQIQAAAAAAgIQIAQAAAAAAJEQIAAAAAAAgIUIAAAAAAAAJEQIAAAAAAEiIEAAAAAAAQEKEAAAAAAAAEiIEAAAAAACQECEAAAAAAICECAEAAAAAACRECAAAAAAAICFCAAAAAAAACRECAAAAAABIiBAAAAAAAEBChAAAAAAAABIiBAAAAAAAkBAhAAAAAACAhAgBAAAAAAAkRAgAAAAAACAhQgAAAAAAAAkRAgAAAAAASIgQAAAAAABAQoQAAAAAAAASIgQAAAAAAJAQIQAAAAAAgIQIAQAAAAAAJEQIAAAAAAAgIUIAAAAAAAAJEQIAAAAAAEiIEAAAAAAAQEKEAAAAAAAAEiIEAAAAAACQECEAAAAAAICECAEAAAAAACRECAAAAAAAIPH1nYfO3afgW+ywwQ4b7LDBDs+zwQY7bLDDBjtssMMGO2ywwwY7bLDDBjs8zwYtNyEAAAAAAICECAEAAAAAACSuc47bJgAAAAAAwO3chAAAAAAAABIiBAAAAAAAkBAhAAAAAACAhAgBAAAAAAAkRAgAAAAAACAhQgAAAAAAAAkRAgAAAAAASIgQAAAAAABAQoQAAAAAAAAS/wDj9li3dd+N+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 2000x600 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(1,16,1)\n",
    "plt.imshow(np_prediction[0])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,2)\n",
    "plt.imshow(np_prediction[1])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,3)\n",
    "plt.imshow(np_prediction[2])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,4)\n",
    "plt.imshow(np_prediction[3])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,5)\n",
    "plt.imshow(np_prediction[4])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,6)\n",
    "plt.imshow(np_prediction[5])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,7)\n",
    "plt.imshow(np_prediction[6])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,8)\n",
    "plt.imshow(np_prediction[7])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,9)\n",
    "plt.imshow(np_prediction[8])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,10)\n",
    "plt.imshow(np_prediction[9])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,11)\n",
    "plt.imshow(np_prediction[10])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,12)\n",
    "plt.imshow(np_prediction[11])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,13)\n",
    "plt.imshow(np_prediction[12])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,14)\n",
    "plt.imshow(np_prediction[13])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,15)\n",
    "plt.imshow(np_prediction[14])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,16,16)\n",
    "plt.imshow(np_prediction[15])\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff503ca0-af72-4e5e-958f-f8d52e497340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save so that we can do fvd with other version of pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05bb1d70-fc1c-40a5-8bcd-adaeb1164dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/ca15/hgn-pytorch/three_body_colors/generated_imgs/\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/data/ca15/hgn-pytorch/'\n",
    "generated_imgs_dir = data_dir + dataset_name + '/generated_imgs/'\n",
    "input_frames = trainer.params['optimization']['input_frames']\n",
    "# trainer.hgn = torch.nn.DataParallel(trainer.hgn, device_ids = [1, 2])\n",
    "# trainer.hgn.to(trainer.device)\n",
    "print(generated_imgs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f434a7ef-1200-45ea-ab89-3b582884104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(generated_imgs_dir):\n",
    "    os.makedirs(generated_imgs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad68b97-1767-4f67-8c93-e16f86f6048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random batch\n",
    "dataloader = iter(trainer.test_data_loader)\n",
    "n = int(2048 / 16 * 5)\n",
    "for i in range(n):\n",
    "    data = next(dataloader).to(trainer.device).type(trainer.dtype)\n",
    "    # print(data.shape)\n",
    "    hgn_output = trainer.hgn.forward(rollout_batch=data[:, :input_frames], n_steps=16, variational=False)\n",
    "    prediction = hgn_output.reconstructed_rollout\n",
    "    # print(prediction.shape)\n",
    "    filename = str(i).zfill(4)\n",
    "    # print(filename)\n",
    "    np.save(generated_imgs_dir + filename, prediction[:, 1:].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c3407-9e4c-48aa-842f-7aefdddf4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pendulum, mass_spring, double_pendulum, two_body, three_body"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
